{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if we are using GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 1.15.0\n",
      "Keras Version: 2.2.4-tf\n",
      "\n",
      "Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.0.1\n",
      "Scikit-Learn 0.22.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Training Loop file for StyleGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_loop.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_loop.py \n",
    "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "# 4.0 International License. To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "\"\"\"Main training script.\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "from dnnlib.tflib.autosummary import autosummary\n",
    "\n",
    "import config\n",
    "import train\n",
    "from training import dataset\n",
    "from training import misc\n",
    "from metrics import metric_base\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Just-in-time processing of training images before feeding them to the networks.\n",
    "\n",
    "def process_reals(x, lod, mirror_augment, drange_data, drange_net):\n",
    "    with tf.name_scope('ProcessReals'):\n",
    "        with tf.name_scope('DynamicRange'):\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
    "        if mirror_augment:\n",
    "            with tf.name_scope('MirrorAugment'):\n",
    "                s = tf.shape(x)\n",
    "                mask = tf.random_uniform([s[0], 1, 1, 1], 0.0, 1.0)\n",
    "                mask = tf.tile(mask, [1, s[1], s[2], s[3]])\n",
    "                x = tf.where(mask < 0.5, x, tf.reverse(x, axis=[3]))\n",
    "        with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
    "            s = tf.shape(x)\n",
    "            y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
    "            y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
    "            y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
    "            y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
    "            x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
    "        with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
    "            s = tf.shape(x)\n",
    "            factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
    "            x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
    "            x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
    "            x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
    "        return x\n",
    "    \n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Evaluate time-varying training parameters.\n",
    "\n",
    "def training_schedule(\n",
    "    cur_nimg,\n",
    "    training_set,\n",
    "    num_gpus,\n",
    "    lod_initial_resolution  = 4,        # Image resolution used at the beginning.\n",
    "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
    "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
    "    minibatch_base          = 16,       # Maximum minibatch size, divided evenly among GPUs.\n",
    "    minibatch_dict          = {},       # Resolution-specific overrides.\n",
    "    max_minibatch_per_gpu   = {},       # Resolution-specific maximum minibatch size per GPU.\n",
    "    G_lrate_base            = 0.001,    # Learning rate for the generator.\n",
    "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
    "    D_lrate_base            = 0.001,    # Learning rate for the discriminator.\n",
    "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
    "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
    "    tick_kimg_base          = 160,      # Default interval of progress snapshots.\n",
    "    tick_kimg_dict          = {4: 160, 8:140, 16:120, 32:100, 64:80, 128:60, 256:40, 512:30, 1024:20}): # Resolution-specific overrides.\n",
    "    \n",
    "    \n",
    "    # Initialize result dict.\n",
    "    s = dnnlib.EasyDict()\n",
    "    s.kimg = cur_nimg / 1000.0\n",
    "\n",
    "    # Training phase.\n",
    "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
    "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
    "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
    "\n",
    "    # Level-of-detail and resolution.\n",
    "    s.lod = training_set.resolution_log2\n",
    "    s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
    "    s.lod -= phase_idx\n",
    "    if lod_transition_kimg > 0:\n",
    "        s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
    "    s.lod = max(s.lod, 0.0)\n",
    "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
    "\n",
    "    # Minibatch size.\n",
    "    s.minibatch = minibatch_dict.get(s.resolution, minibatch_base)\n",
    "    s.minibatch -= s.minibatch % num_gpus\n",
    "    if s.resolution in max_minibatch_per_gpu:\n",
    "        s.minibatch = min(s.minibatch, max_minibatch_per_gpu[s.resolution] * num_gpus)\n",
    "\n",
    "    # Learning rate.\n",
    "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
    "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
    "    if lrate_rampup_kimg > 0:\n",
    "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
    "        s.G_lrate *= rampup\n",
    "        s.D_lrate *= rampup\n",
    "        \n",
    "    # Other parameters.\n",
    "    s.tick_kimg = tick_kimg_dict.get(s.resolution, tick_kimg_base)\n",
    "    return s\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Main training script.\n",
    "\n",
    "def training_loop(\n",
    "    submit_config,\n",
    "    G_args                  = {},       # Options for generator network.\n",
    "    D_args                  = {},       # Options for discriminator network.\n",
    "    G_opt_args              = {},       # Options for generator optimizer.\n",
    "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
    "    G_loss_args             = {},       # Options for generator loss.\n",
    "    D_loss_args             = {},       # Options for discriminator loss.\n",
    "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
    "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
    "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
    "    metric_arg_list         = [],       # Options for MetricGroup.\n",
    "    tf_config               = {},       # Options for tflib.init_tf().\n",
    "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
    "    D_repeats               = 1,        # How many times the discriminator is trained per G iteration.\n",
    "    minibatch_repeats       = 1,        # Number of minibatches to run before adjusting training parameters.\n",
    "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
    "    total_kimg              = 15000,    # Total length of the training, measured in thousands of real images.\n",
    "    mirror_augment          = False,    # Enable mirror augment?\n",
    "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
    "    image_snapshot_ticks    = 1,        # How often to export image snapshots?\n",
    "    network_snapshot_ticks  = 1,       # How often to export network snapshots?\n",
    "    save_tf_graph           = True,    # Include full TensorFlow computation graph in the tfevents file?\n",
    "    save_weight_histograms  = True,    # Include weight histograms in the tfevents file?\n",
    "    resume_run_id           = \"C:\\\\Users\\\\jvhua\\\\OneDrive\\\\Desktop\\\\mhxx-armor\\\\stylegan\\\\network-snapshot-007440.pkl\", # Run ID or network pkl to resume training from, None = start from scratch.\n",
    "    resume_snapshot         = None,     # Snapshot index to resume training from, None = autodetect.\n",
    "    resume_kimg             = 11125,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
    "    resume_time             = 0.0):     # Assumed wallclock time at the beginning. Affects reporting.\n",
    "\n",
    "    # Initialize dnnlib and TensorFlow.\n",
    "    ctx = dnnlib.RunContext(submit_config, train)\n",
    "    tflib.init_tf(tf_config)\n",
    "\n",
    "    # Load training set.\n",
    "    training_set = dataset.load_dataset(data_dir=config.data_dir, verbose=True, **dataset_args)\n",
    "\n",
    "    # Construct networks.\n",
    "    with tf.device('/gpu:0'):\n",
    "        if resume_run_id is not None:\n",
    "            network_pkl = misc.locate_network_pkl(resume_run_id, resume_snapshot)\n",
    "            print('Loading networks from \"%s\"...' % network_pkl)\n",
    "            G, D, Gs = misc.load_pkl(network_pkl)\n",
    "        else:\n",
    "            print('Constructing networks...')\n",
    "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
    "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
    "            Gs = G.clone('Gs')\n",
    "    G.print_layers(); D.print_layers()\n",
    "\n",
    "    print('Building TensorFlow graph...')\n",
    "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
    "        lod_in          = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
    "        lrate_in        = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
    "        minibatch_in    = tf.placeholder(tf.int32, name='minibatch_in', shape=[])\n",
    "        minibatch_split = minibatch_in // submit_config.num_gpus\n",
    "        Gs_beta         = 0.5 ** tf.div(tf.cast(minibatch_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
    "\n",
    "    G_opt = tflib.Optimizer(name='TrainG', learning_rate=lrate_in, **G_opt_args)\n",
    "    D_opt = tflib.Optimizer(name='TrainD', learning_rate=lrate_in, **D_opt_args)\n",
    "    for gpu in range(submit_config.num_gpus):\n",
    "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
    "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
    "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
    "            lod_assign_ops = [tf.assign(G_gpu.find_var('lod'), lod_in), tf.assign(D_gpu.find_var('lod'), lod_in)]\n",
    "            reals, labels = training_set.get_minibatch_tf()\n",
    "            reals = process_reals(reals, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
    "            with tf.name_scope('G_loss'), tf.control_dependencies(lod_assign_ops):\n",
    "                G_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_split, **G_loss_args)\n",
    "            with tf.name_scope('D_loss'), tf.control_dependencies(lod_assign_ops):\n",
    "                D_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_split, reals=reals, labels=labels, **D_loss_args)\n",
    "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
    "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
    "    G_train_op = G_opt.apply_updates()\n",
    "    D_train_op = D_opt.apply_updates()\n",
    "\n",
    "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
    "    with tf.device('/gpu:0'):\n",
    "        try:\n",
    "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
    "        except tf.errors.NotFoundError:\n",
    "            peak_gpu_mem_op = tf.constant(0)\n",
    "\n",
    "    print('Setting up snapshot image grid...')\n",
    "    grid_size, grid_reals, grid_labels, grid_latents = misc.setup_snapshot_image_grid(G, training_set, **grid_args)\n",
    "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
    "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
    "    \n",
    "    print('Setting up run dir...')\n",
    "    misc.save_image_grid(grid_reals, os.path.join(submit_config.run_dir, 'reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
    "    misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % resume_kimg), drange=drange_net, grid_size=grid_size)\n",
    "    summary_log = tf.summary.FileWriter(submit_config.run_dir)\n",
    "    if save_tf_graph:\n",
    "        summary_log.add_graph(tf.get_default_graph())\n",
    "    if save_weight_histograms:\n",
    "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
    "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
    "\n",
    "    print('Training...\\n')\n",
    "    ctx.update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
    "    maintenance_time = ctx.get_last_update_interval()\n",
    "    cur_nimg = int(resume_kimg * 1000)\n",
    "    cur_tick = 0\n",
    "    tick_start_nimg = cur_nimg\n",
    "    prev_lod = -1.0\n",
    "    while cur_nimg < total_kimg * 1000:\n",
    "        if ctx.should_stop(): break\n",
    "\n",
    "        # Choose training parameters and configure training ops.\n",
    "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
    "        training_set.configure(sched.minibatch // submit_config.num_gpus, sched.lod)\n",
    "        if reset_opt_for_new_lod:\n",
    "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
    "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
    "        prev_lod = sched.lod\n",
    "\n",
    "        # Run training ops.\n",
    "        for _mb_repeat in range(minibatch_repeats):\n",
    "            for _D_repeat in range(D_repeats):\n",
    "                tflib.run([D_train_op, Gs_update_op], {lod_in: sched.lod, lrate_in: sched.D_lrate, minibatch_in: sched.minibatch})\n",
    "                cur_nimg += sched.minibatch\n",
    "            tflib.run([G_train_op], {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_in: sched.minibatch})\n",
    "\n",
    "        # Perform maintenance tasks once per tick.\n",
    "        done = (cur_nimg >= total_kimg * 1000)\n",
    "        if cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
    "            cur_tick += 1\n",
    "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
    "            tick_start_nimg = cur_nimg\n",
    "            tick_time = ctx.get_time_since_last_update()\n",
    "            total_time = ctx.get_time_since_start() + resume_time\n",
    "\n",
    "            # Report progress.\n",
    "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %-4.1f' % (\n",
    "                autosummary('Progress/tick', cur_tick),\n",
    "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
    "                autosummary('Progress/lod', sched.lod),\n",
    "                autosummary('Progress/minibatch', sched.minibatch),\n",
    "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
    "                autosummary('Timing/sec_per_tick', tick_time),\n",
    "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
    "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
    "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
    "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
    "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
    "\n",
    "            # Save snapshots.\n",
    "            if cur_tick % image_snapshot_ticks == 0 or done:\n",
    "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
    "                misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % (cur_nimg // 1000)), drange=drange_net, grid_size=grid_size)\n",
    "            if cur_tick % network_snapshot_ticks == 0 or done or cur_tick == 1:\n",
    "                pkl = os.path.join(submit_config.run_dir, 'network-snapshot-%06d.pkl' % (cur_nimg // 1000))\n",
    "                misc.save_pkl((G, D, Gs), pkl)\n",
    "                metrics.run(pkl, run_dir=submit_config.run_dir, num_gpus=submit_config.num_gpus, tf_config=tf_config)\n",
    "\n",
    "            # Update summaries and RunContext.\n",
    "            metrics.update_autosummaries()\n",
    "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
    "            ctx.update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
    "            maintenance_time = ctx.get_last_update_interval() - tick_time\n",
    "\n",
    "    # Write final results.\n",
    "    misc.save_pkl((G, D, Gs), os.path.join(submit_config.run_dir, 'network-final.pkl'))\n",
    "    summary_log.close()\n",
    "\n",
    "    ctx.close()\n",
    "\n",
    "#----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Creating the run dir: results\\00002-sgan-custom-1gpu\n",
      "Copying files to the run dir\n",
      "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Streaming data using training.dataset.TFRecordDataset...\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:75: The name tf.python_io.TFRecordOptions is deprecated. Please use tf.io.TFRecordOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:75: The name tf.python_io.TFRecordCompressionType is deprecated. Please use tf.compat.v1.python_io.TFRecordCompressionType instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:76: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:114: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:196: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:200: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:132: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:132: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\dataset.py:132: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\Miniconda3\\envs\\tensflow\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "Dataset shape = [3, 256, 256]\n",
      "Dynamic range = [0, 255]\n",
      "Label size    = 0\n",
      "Constructing networks...\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\network.py:150: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\tfutil.py:76: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\network.py:151: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\networks_stylegan.py:479: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\networks_stylegan.py:254: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\network.py:182: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "lod                           -         ()                  -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "G_mapping/latents_in          -         (?, 512)            -               \n",
      "G_mapping/labels_in           -         (?, 0)              -               \n",
      "G_mapping/PixelNorm           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 14, 512)        -               \n",
      "G_mapping/dlatents_out        -         (?, 14, 512)        -               \n",
      "Truncation                    -         (?, 14, 512)        -               \n",
      "G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_synthesis/4x4/Const         534528    (?, 512, 4, 4)      (512,)          \n",
      "G_synthesis/4x4/Conv          2885632   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod6        1539      (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod5        1539      (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D         -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/Grow_lod5         -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/16x16/Conv0_up    2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod4        1539      (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D_1       -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/Grow_lod4         -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/32x32/Conv0_up    2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod3        1539      (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D_2       -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/Grow_lod3         -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/64x64/Conv0_up    1442816   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       852992    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/ToRGB_lod2        771       (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/Upscale2D_3       -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/Grow_lod2         -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/128x128/Conv0_up  426496    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     279040    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/ToRGB_lod1        387       (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "G_synthesis/Upscale2D_4       -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/Grow_lod1         -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/256x256/Conv0_up  139520    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
      "G_synthesis/256x256/Conv1     102656    (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "G_synthesis/ToRGB_lod0        195       (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
      "G_synthesis/Upscale2D_5       -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/Grow_lod0         -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/images_out        -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/lod               -         ()                  -               \n",
      "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
      "G_synthesis/noise1            -         (1, 1, 4, 4)        -               \n",
      "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
      "G_synthesis/noise3            -         (1, 1, 8, 8)        -               \n",
      "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
      "G_synthesis/noise5            -         (1, 1, 16, 16)      -               \n",
      "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
      "G_synthesis/noise7            -         (1, 1, 32, 32)      -               \n",
      "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
      "G_synthesis/noise9            -         (1, 1, 64, 64)      -               \n",
      "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
      "G_synthesis/noise11           -         (1, 1, 128, 128)    -               \n",
      "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
      "G_synthesis/noise13           -         (1, 1, 256, 256)    -               \n",
      "images_out                    -         (?, 3, 256, 256)    -               \n",
      "---                           ---       ---                 ---             \n",
      "Total                         26086229                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 256, 256)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "lod                  -         ()                  -               \n",
      "FromRGB_lod0         256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
      "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
      "Downscale2D          -         (?, 3, 128, 128)    -               \n",
      "FromRGB_lod1         512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "Grow_lod0            -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "Downscale2D_1        -         (?, 3, 64, 64)      -               \n",
      "FromRGB_lod2         1024      (?, 256, 64, 64)    (1, 1, 3, 256)  \n",
      "Grow_lod1            -         (?, 256, 64, 64)    -               \n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "Downscale2D_2        -         (?, 3, 32, 32)      -               \n",
      "FromRGB_lod3         2048      (?, 512, 32, 32)    (1, 1, 3, 512)  \n",
      "Grow_lod2            -         (?, 512, 32, 32)    -               \n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "Downscale2D_3        -         (?, 3, 16, 16)      -               \n",
      "FromRGB_lod4         2048      (?, 512, 16, 16)    (1, 1, 3, 512)  \n",
      "Grow_lod3            -         (?, 512, 16, 16)    -               \n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "Downscale2D_4        -         (?, 3, 8, 8)        -               \n",
      "FromRGB_lod5         2048      (?, 512, 8, 8)      (1, 1, 3, 512)  \n",
      "Grow_lod4            -         (?, 512, 8, 8)      -               \n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "Downscale2D_5        -         (?, 3, 4, 4)        -               \n",
      "FromRGB_lod6         2048      (?, 512, 4, 4)      (1, 1, 3, 512)  \n",
      "Grow_lod5            -         (?, 512, 4, 4)      -               \n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "4x4/Dense1           513       (?, 1)              (512, 1)        \n",
      "scores_out           -         (?, 1)              -               \n",
      "---                  ---       ---                 ---             \n",
      "Total                23052353                                      \n",
      "\n",
      "Building TensorFlow graph...\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\training_loop.py:167: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\util.py:242: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\training_loop.py:34: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\loss.py:132: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\networks_stylegan.py:90: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\autosummary.py:61: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\autosummary.py:65: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\autosummary.py:65: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\optimizer.py:98: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Setting up snapshot image grid...\n",
      "Setting up run dir...\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\training\\training_loop.py:202: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Training...\n",
      "\n",
      "tick 1     kimg 140.3    lod 5.00  minibatch 128  time 4m 14s       sec/tick 215.0   sec/kimg 1.53    maintenance 38.9   gpumem 3.0 \n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\autosummary.py:137: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jvhua\\OneDrive\\Desktop\\mhxx-armor\\stylegan\\dnnlib\\tflib\\autosummary.py:182: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "tick 2     kimg 280.6    lod 5.00  minibatch 128  time 7m 57s       sec/tick 211.3   sec/kimg 1.51    maintenance 11.9   gpumem 3.0 \n",
      "tick 3     kimg 420.9    lod 5.00  minibatch 128  time 11m 32s      sec/tick 212.3   sec/kimg 1.51    maintenance 2.1    gpumem 3.0 \n",
      "tick 4     kimg 561.2    lod 5.00  minibatch 128  time 15m 01s      sec/tick 207.5   sec/kimg 1.48    maintenance 2.0    gpumem 3.0 \n",
      "tick 5     kimg 681.5    lod 4.87  minibatch 128  time 21m 57s      sec/tick 414.3   sec/kimg 3.44    maintenance 1.6    gpumem 4.9 \n",
      "tick 6     kimg 801.8    lod 4.66  minibatch 128  time 30m 34s      sec/tick 515.1   sec/kimg 4.28    maintenance 2.1    gpumem 4.9 \n",
      "tick 7     kimg 922.1    lod 4.46  minibatch 128  time 39m 12s      sec/tick 516.1   sec/kimg 4.29    maintenance 1.7    gpumem 4.9 \n",
      "tick 8     kimg 1042.4   lod 4.26  minibatch 128  time 47m 49s      sec/tick 515.5   sec/kimg 4.28    maintenance 1.6    gpumem 4.9 \n",
      "tick 9     kimg 1162.8   lod 4.06  minibatch 128  time 56m 26s      sec/tick 514.8   sec/kimg 4.28    maintenance 1.6    gpumem 4.9 \n",
      "tick 10    kimg 1283.1   lod 4.00  minibatch 128  time 1h 04m 55s   sec/tick 508.3   sec/kimg 4.22    maintenance 1.6    gpumem 4.9 \n",
      "tick 11    kimg 1403.4   lod 4.00  minibatch 128  time 1h 13m 23s   sec/tick 505.5   sec/kimg 4.20    maintenance 1.9    gpumem 4.9 \n",
      "tick 12    kimg 1523.7   lod 4.00  minibatch 128  time 1h 21m 50s   sec/tick 505.2   sec/kimg 4.20    maintenance 1.6    gpumem 4.9 \n",
      "tick 13    kimg 1644.0   lod 4.00  minibatch 128  time 1h 30m 17s   sec/tick 505.1   sec/kimg 4.20    maintenance 1.6    gpumem 4.9 \n",
      "tick 14    kimg 1764.4   lod 4.00  minibatch 128  time 1h 38m 43s   sec/tick 504.8   sec/kimg 4.20    maintenance 1.6    gpumem 4.9 \n",
      "tick 15    kimg 1864.4   lod 3.89  minibatch 64   time 1h 58m 44s   sec/tick 1199.2  sec/kimg 11.98   maintenance 1.6    gpumem 4.9 \n",
      "tick 16    kimg 1964.5   lod 3.73  minibatch 64   time 2h 25m 50s   sec/tick 1623.8  sec/kimg 16.22   maintenance 2.8    gpumem 4.9 \n",
      "tick 17    kimg 2064.6   lod 3.56  minibatch 64   time 2h 52m 55s   sec/tick 1623.0  sec/kimg 16.21   maintenance 1.7    gpumem 4.9 \n",
      "tick 18    kimg 2164.7   lod 3.39  minibatch 64   time 3h 20m 03s   sec/tick 1625.7  sec/kimg 16.24   maintenance 1.7    gpumem 4.9 \n",
      "tick 19    kimg 2264.8   lod 3.23  minibatch 64   time 3h 47m 08s   sec/tick 1623.7  sec/kimg 16.22   maintenance 1.8    gpumem 4.9 \n",
      "tick 20    kimg 2364.9   lod 3.06  minibatch 64   time 4h 14m 12s   sec/tick 1622.3  sec/kimg 16.21   maintenance 1.8    gpumem 4.9 \n",
      "tick 21    kimg 2465.0   lod 3.00  minibatch 64   time 4h 41m 02s   sec/tick 1607.6  sec/kimg 16.06   maintenance 2.1    gpumem 4.9 \n",
      "tick 22    kimg 2565.1   lod 3.00  minibatch 64   time 5h 07m 43s   sec/tick 1599.6  sec/kimg 15.98   maintenance 1.8    gpumem 4.9 \n",
      "tick 23    kimg 2665.2   lod 3.00  minibatch 64   time 5h 34m 24s   sec/tick 1598.6  sec/kimg 15.97   maintenance 1.8    gpumem 4.9 \n",
      "tick 24    kimg 2765.3   lod 3.00  minibatch 64   time 6h 01m 02s   sec/tick 1596.4  sec/kimg 15.95   maintenance 1.8    gpumem 4.9 \n",
      "tick 25    kimg 2865.4   lod 3.00  minibatch 64   time 6h 27m 41s   sec/tick 1596.6  sec/kimg 15.95   maintenance 1.8    gpumem 4.9 \n",
      "tick 26    kimg 2965.5   lod 3.00  minibatch 64   time 6h 54m 23s   sec/tick 1600.4  sec/kimg 15.99   maintenance 1.8    gpumem 4.9 \n",
      "tick 27    kimg 3045.5   lod 2.92  minibatch 32   time 7h 32m 32s   sec/tick 2288.0  sec/kimg 28.60   maintenance 1.8    gpumem 5.1 \n",
      "tick 28    kimg 3125.5   lod 2.79  minibatch 32   time 8h 23m 25s   sec/tick 3049.1  sec/kimg 38.11   maintenance 3.4    gpumem 5.1 \n",
      "tick 29    kimg 3205.5   lod 2.66  minibatch 32   time 9h 14m 26s   sec/tick 3059.0  sec/kimg 38.24   maintenance 2.1    gpumem 5.1 \n",
      "tick 30    kimg 3285.5   lod 2.52  minibatch 32   time 10h 05m 26s  sec/tick 3057.8  sec/kimg 38.22   maintenance 2.1    gpumem 5.1 \n",
      "tick 31    kimg 3365.5   lod 2.39  minibatch 32   time 10h 56m 14s  sec/tick 3045.9  sec/kimg 38.07   maintenance 2.4    gpumem 5.1 \n",
      "tick 32    kimg 3445.5   lod 2.26  minibatch 32   time 11h 47m 05s  sec/tick 3049.1  sec/kimg 38.11   maintenance 2.1    gpumem 5.1 \n",
      "tick 33    kimg 3525.5   lod 2.12  minibatch 32   time 12h 38m 10s  sec/tick 3062.4  sec/kimg 38.28   maintenance 2.1    gpumem 5.1 \n",
      "tick 34    kimg 3605.5   lod 2.00  minibatch 32   time 13h 29m 28s  sec/tick 3075.7  sec/kimg 38.45   maintenance 2.2    gpumem 5.1 \n",
      "tick 35    kimg 3685.5   lod 2.00  minibatch 32   time 14h 19m 45s  sec/tick 3014.9  sec/kimg 37.69   maintenance 2.1    gpumem 5.1 \n",
      "tick 36    kimg 3765.5   lod 2.00  minibatch 32   time 15h 10m 03s  sec/tick 3016.4  sec/kimg 37.71   maintenance 2.1    gpumem 5.1 \n",
      "tick 37    kimg 3845.5   lod 2.00  minibatch 32   time 16h 00m 18s  sec/tick 3013.0  sec/kimg 37.66   maintenance 2.1    gpumem 5.1 \n",
      "tick 38    kimg 3925.5   lod 2.00  minibatch 32   time 16h 50m 25s  sec/tick 3004.2  sec/kimg 37.55   maintenance 2.1    gpumem 5.1 \n",
      "tick 39    kimg 4005.5   lod 2.00  minibatch 32   time 17h 40m 27s  sec/tick 3000.5  sec/kimg 37.51   maintenance 2.1    gpumem 5.1 \n",
      "tick 40    kimg 4085.5   lod 2.00  minibatch 32   time 18h 30m 43s  sec/tick 3013.3  sec/kimg 37.67   maintenance 2.1    gpumem 5.1 \n",
      "tick 41    kimg 4165.5   lod 2.00  minibatch 32   time 19h 20m 50s  sec/tick 3004.9  sec/kimg 37.56   maintenance 2.5    gpumem 5.1 \n",
      "tick 42    kimg 4225.5   lod 1.96  minibatch 16   time 20h 14m 51s  sec/tick 3238.9  sec/kimg 53.95   maintenance 2.1    gpumem 5.1 \n",
      "tick 43    kimg 4285.6   lod 1.86  minibatch 16   time 21h 31m 40s  sec/tick 4606.1  sec/kimg 76.73   maintenance 3.2    gpumem 5.1 \n",
      "tick 44    kimg 4345.6   lod 1.76  minibatch 16   time 22h 47m 33s  sec/tick 4549.1  sec/kimg 75.78   maintenance 3.5    gpumem 5.1 \n",
      "tick 45    kimg 4405.6   lod 1.66  minibatch 16   time 1d 00h 03m   sec/tick 4555.2  sec/kimg 75.88   maintenance 3.4    gpumem 5.1 \n",
      "tick 46    kimg 4465.7   lod 1.56  minibatch 16   time 1d 01h 19m   sec/tick 4553.7  sec/kimg 75.85   maintenance 3.5    gpumem 5.1 \n",
      "tick 47    kimg 4525.7   lod 1.46  minibatch 16   time 1d 02h 35m   sec/tick 4553.2  sec/kimg 75.85   maintenance 3.5    gpumem 5.1 \n",
      "tick 48    kimg 4585.7   lod 1.36  minibatch 16   time 1d 03h 51m   sec/tick 4557.4  sec/kimg 75.92   maintenance 3.5    gpumem 5.1 \n",
      "tick 49    kimg 4645.8   lod 1.26  minibatch 16   time 1d 05h 07m   sec/tick 4550.8  sec/kimg 75.81   maintenance 3.6    gpumem 5.1 \n",
      "tick 50    kimg 4705.8   lod 1.16  minibatch 16   time 1d 06h 23m   sec/tick 4556.7  sec/kimg 75.90   maintenance 3.7    gpumem 5.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tick 51    kimg 4765.8   lod 1.06  minibatch 16   time 1d 07h 39m   sec/tick 4544.9  sec/kimg 75.71   maintenance 4.1    gpumem 5.1 \n",
      "tick 52    kimg 4825.9   lod 1.00  minibatch 16   time 1d 08h 54m   sec/tick 4525.3  sec/kimg 75.38   maintenance 3.6    gpumem 5.1 \n",
      "tick 53    kimg 4885.9   lod 1.00  minibatch 16   time 1d 10h 09m   sec/tick 4502.8  sec/kimg 75.01   maintenance 3.7    gpumem 5.1 \n",
      "tick 54    kimg 4945.9   lod 1.00  minibatch 16   time 1d 11h 25m   sec/tick 4532.8  sec/kimg 75.51   maintenance 3.7    gpumem 5.1 \n",
      "tick 55    kimg 5006.0   lod 1.00  minibatch 16   time 1d 12h 41m   sec/tick 4551.9  sec/kimg 75.82   maintenance 3.8    gpumem 5.1 \n",
      "tick 56    kimg 5066.0   lod 1.00  minibatch 16   time 1d 13h 57m   sec/tick 4551.9  sec/kimg 75.82   maintenance 3.8    gpumem 5.1 \n",
      "tick 57    kimg 5126.0   lod 1.00  minibatch 16   time 1d 15h 12m   sec/tick 4484.7  sec/kimg 74.70   maintenance 3.7    gpumem 5.1 \n",
      "tick 58    kimg 5186.0   lod 1.00  minibatch 16   time 1d 16h 27m   sec/tick 4503.2  sec/kimg 75.01   maintenance 3.7    gpumem 5.1 \n",
      "tick 59    kimg 5246.1   lod 1.00  minibatch 16   time 1d 17h 42m   sec/tick 4499.2  sec/kimg 74.95   maintenance 3.7    gpumem 5.1 \n",
      "tick 60    kimg 5306.1   lod 1.00  minibatch 16   time 1d 18h 57m   sec/tick 4504.7  sec/kimg 75.04   maintenance 3.7    gpumem 5.1 \n",
      "tick 61    kimg 5366.1   lod 1.00  minibatch 16   time 1d 20h 12m   sec/tick 4505.3  sec/kimg 75.05   maintenance 4.2    gpumem 5.1 \n",
      "tick 62    kimg 5406.1   lod 0.99  minibatch 8    time 1d 21h 10m   sec/tick 3475.3  sec/kimg 86.88   maintenance 3.7    gpumem 5.1 \n",
      "tick 63    kimg 5446.1   lod 0.92  minibatch 8    time 1d 22h 50m   sec/tick 6022.2  sec/kimg 150.55  maintenance 5.2    gpumem 5.1 \n",
      "tick 64    kimg 5486.1   lod 0.86  minibatch 8    time 2d 00h 31m   sec/tick 6056.5  sec/kimg 151.41  maintenance 6.3    gpumem 5.1 \n",
      "tick 65    kimg 5526.1   lod 0.79  minibatch 8    time 2d 02h 14m   sec/tick 6128.6  sec/kimg 153.22  maintenance 6.0    gpumem 5.1 \n",
      "tick 66    kimg 5566.1   lod 0.72  minibatch 8    time 2d 03h 56m   sec/tick 6117.9  sec/kimg 152.95  maintenance 5.8    gpumem 5.1 \n",
      "tick 67    kimg 5606.1   lod 0.66  minibatch 8    time 2d 05h 38m   sec/tick 6105.6  sec/kimg 152.64  maintenance 5.8    gpumem 5.1 \n",
      "tick 68    kimg 5646.1   lod 0.59  minibatch 8    time 2d 07h 19m   sec/tick 6067.5  sec/kimg 151.69  maintenance 5.6    gpumem 5.1 \n",
      "tick 69    kimg 5686.1   lod 0.52  minibatch 8    time 2d 09h 01m   sec/tick 6098.3  sec/kimg 152.46  maintenance 5.6    gpumem 5.1 \n",
      "tick 70    kimg 5726.1   lod 0.46  minibatch 8    time 2d 10h 44m   sec/tick 6194.2  sec/kimg 154.86  maintenance 5.6    gpumem 5.1 \n",
      "tick 71    kimg 5766.1   lod 0.39  minibatch 8    time 2d 12h 27m   sec/tick 6196.5  sec/kimg 154.91  maintenance 6.0    gpumem 5.1 \n",
      "tick 72    kimg 5806.1   lod 0.32  minibatch 8    time 2d 14h 10m   sec/tick 6170.0  sec/kimg 154.25  maintenance 5.5    gpumem 5.1 \n",
      "tick 73    kimg 5846.1   lod 0.26  minibatch 8    time 2d 15h 52m   sec/tick 6096.5  sec/kimg 152.41  maintenance 5.6    gpumem 5.1 \n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "# 4.0 International License. To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "\"\"\"Main entry point for training StyleGAN and ProGAN networks.\"\"\"\n",
    "\n",
    "import copy\n",
    "import dnnlib\n",
    "from dnnlib import EasyDict\n",
    "\n",
    "import config\n",
    "from metrics import metric_base\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Official training configs for StyleGAN, targeted mainly for FFHQ.\n",
    "\n",
    "if 1:\n",
    "    desc          = 'sgan'                                                                 # Description string included in result subdir name.\n",
    "    train         = EasyDict(run_func_name='training.training_loop.training_loop')         # Options for training loop.\n",
    "    G             = EasyDict(func_name='training.networks_stylegan.G_style')               # Options for generator network.\n",
    "    D             = EasyDict(func_name='training.networks_stylegan.D_basic')               # Options for discriminator network.\n",
    "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for generator optimizer.\n",
    "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for discriminator optimizer.\n",
    "    G_loss        = EasyDict(func_name='training.loss.G_logistic_nonsaturating')           # Options for generator loss.\n",
    "    D_loss        = EasyDict(func_name='training.loss.D_logistic_simplegp', r1_gamma=10.0) # Options for discriminator loss.\n",
    "    dataset       = EasyDict()                                                             # Options for load_dataset().\n",
    "    sched         = EasyDict()                                                             # Options for TrainingSchedule.\n",
    "    grid          = EasyDict(size='4k', layout='random')                                   # Options for setup_snapshot_image_grid().\n",
    "    #metrics       = [metric_base.fid50k]                                                   # Options for MetricGroup.\n",
    "    submit_config = dnnlib.SubmitConfig()                                                  # Options for dnnlib.submit_run().\n",
    "    tf_config     = {'rnd.np_random_seed': 1000}                                           # Options for tflib.init_tf().\n",
    "\n",
    "    # Dataset.\n",
    "    desc += '-custom';     dataset = EasyDict(tfrecord_dir='C:\\\\Users\\\\jvhua\\\\OneDrive\\Desktop\\\\mhxx-armor\\\\stylegan\\\\dataset\\\\armor_256', resolution = 256);              train.mirror_augment = True\n",
    "    #desc += '-celebahq'; dataset = EasyDict(tfrecord_dir='celebahq');          train.mirror_augment = True\n",
    "    #desc += '-bedroom';  dataset = EasyDict(tfrecord_dir='lsun-bedroom-full'); train.mirror_augment = False\n",
    "    #desc += '-car';      dataset = EasyDict(tfrecord_dir='lsun-car-512x384');  train.mirror_augment = False\n",
    "    #desc += '-cat';      dataset = EasyDict(tfrecord_dir='lsun-cat-full');     train.mirror_augment = False\n",
    "\n",
    "    # Number of GPUs.\n",
    "    desc += '-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}\n",
    "    #desc += '-2gpu'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}\n",
    "    #desc += '-4gpu'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
    "    #desc += '-8gpu'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
    "\n",
    "    # Default options.\n",
    "    train.total_kimg = 10000\n",
    "    sched.lod_initial_resolution = 8\n",
    "    sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "    sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
    "\n",
    "    # WGAN-GP loss for CelebA-HQ.\n",
    "    #desc += '-wgangp'; G_loss = EasyDict(func_name='training.loss.G_wgan'); D_loss = EasyDict(func_name='training.loss.D_wgan_gp'); sched.G_lrate_dict = {k: min(v, 0.002) for k, v in sched.G_lrate_dict.items()}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
    "\n",
    "    # Table 1.\n",
    "    #desc += '-tuned-baseline'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-add-mapping-and-styles'; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-remove-traditional-input'; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-add-noise-inputs'; G.style_mixing_prob = 0.0\n",
    "    #desc += '-mixing-regularization' # default\n",
    "\n",
    "    # Table 2.\n",
    "    #desc += '-mix0'; G.style_mixing_prob = 0.0\n",
    "    #desc += '-mix50'; G.style_mixing_prob = 0.5\n",
    "    #desc += '-mix90'; G.style_mixing_prob = 0.9 # default\n",
    "    #desc += '-mix100'; G.style_mixing_prob = 1.0\n",
    "\n",
    "    # Table 4.\n",
    "    #desc += '-traditional-0'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-traditional-8'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 8; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-stylebased-0'; G.mapping_layers = 0\n",
    "    #desc += '-stylebased-1'; G.mapping_layers = 1\n",
    "    #desc += '-stylebased-2'; G.mapping_layers = 2\n",
    "    #desc += '-stylebased-8'; G.mapping_layers = 8 # default\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Official training configs for Progressive GAN, targeted mainly for CelebA-HQ.\n",
    "\n",
    "if 0:\n",
    "    desc          = 'pgan'                                                         # Description string included in result subdir name.\n",
    "    train         = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
    "    G             = EasyDict(func_name='training.networks_progan.G_paper')         # Options for generator network.\n",
    "    D             = EasyDict(func_name='training.networks_progan.D_paper')         # Options for discriminator network.\n",
    "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
    "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
    "    G_loss        = EasyDict(func_name='training.loss.G_wgan')                     # Options for generator loss.\n",
    "    D_loss        = EasyDict(func_name='training.loss.D_wgan_gp')                  # Options for discriminator loss.\n",
    "    dataset       = EasyDict()                                                     # Options for load_dataset().\n",
    "    sched         = EasyDict()                                                     # Options for TrainingSchedule.\n",
    "    grid          = EasyDict(size='1080p', layout='random')                        # Options for setup_snapshot_image_grid().\n",
    "    #metrics       = [metric_base.fid50k]                                           # Options for MetricGroup.\n",
    "    submit_config = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
    "    tf_config     = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
    "\n",
    "    # Dataset (choose one).\n",
    "    #desc += '-celebahq';            dataset = EasyDict(tfrecord_dir='celebahq'); train.mirror_augment = True\n",
    "    #desc += '-celeba';              dataset = EasyDict(tfrecord_dir='celeba'); train.mirror_augment = True\n",
    "    #desc += '-cifar10';             dataset = EasyDict(tfrecord_dir='cifar10')\n",
    "    #desc += '-cifar100';            dataset = EasyDict(tfrecord_dir='cifar100')\n",
    "    #desc += '-svhn';                dataset = EasyDict(tfrecord_dir='svhn')\n",
    "    #desc += '-mnist';               dataset = EasyDict(tfrecord_dir='mnist')\n",
    "    #desc += '-mnistrgb';            dataset = EasyDict(tfrecord_dir='mnistrgb')\n",
    "    #desc += '-syn1024rgb';          dataset = EasyDict(class_name='training.dataset.SyntheticDataset', resolution=1024, num_channels=3)\n",
    "    #desc += '-lsun-airplane';       dataset = EasyDict(tfrecord_dir='lsun-airplane-100k');       train.mirror_augment = True\n",
    "    #desc += '-lsun-bedroom';        dataset = EasyDict(tfrecord_dir='lsun-bedroom-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-bicycle';        dataset = EasyDict(tfrecord_dir='lsun-bicycle-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-bird';           dataset = EasyDict(tfrecord_dir='lsun-bird-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-boat';           dataset = EasyDict(tfrecord_dir='lsun-boat-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-bottle';         dataset = EasyDict(tfrecord_dir='lsun-bottle-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-bridge';         dataset = EasyDict(tfrecord_dir='lsun-bridge-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-bus';            dataset = EasyDict(tfrecord_dir='lsun-bus-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-car';            dataset = EasyDict(tfrecord_dir='lsun-car-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-cat';            dataset = EasyDict(tfrecord_dir='lsun-cat-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-chair';          dataset = EasyDict(tfrecord_dir='lsun-chair-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-churchoutdoor';  dataset = EasyDict(tfrecord_dir='lsun-churchoutdoor-100k');  train.mirror_augment = True\n",
    "    #desc += '-lsun-classroom';      dataset = EasyDict(tfrecord_dir='lsun-classroom-100k');      train.mirror_augment = True\n",
    "    #desc += '-lsun-conferenceroom'; dataset = EasyDict(tfrecord_dir='lsun-conferenceroom-100k'); train.mirror_augment = True\n",
    "    #desc += '-lsun-cow';            dataset = EasyDict(tfrecord_dir='lsun-cow-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-diningroom';     dataset = EasyDict(tfrecord_dir='lsun-diningroom-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-diningtable';    dataset = EasyDict(tfrecord_dir='lsun-diningtable-100k');    train.mirror_augment = True\n",
    "    #desc += '-lsun-dog';            dataset = EasyDict(tfrecord_dir='lsun-dog-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-horse';          dataset = EasyDict(tfrecord_dir='lsun-horse-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-kitchen';        dataset = EasyDict(tfrecord_dir='lsun-kitchen-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-livingroom';     dataset = EasyDict(tfrecord_dir='lsun-livingroom-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-motorbike';      dataset = EasyDict(tfrecord_dir='lsun-motorbike-100k');      train.mirror_augment = True\n",
    "    #desc += '-lsun-person';         dataset = EasyDict(tfrecord_dir='lsun-person-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-pottedplant';    dataset = EasyDict(tfrecord_dir='lsun-pottedplant-100k');    train.mirror_augment = True\n",
    "    #desc += '-lsun-restaurant';     dataset = EasyDict(tfrecord_dir='lsun-restaurant-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-sheep';          dataset = EasyDict(tfrecord_dir='lsun-sheep-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-sofa';           dataset = EasyDict(tfrecord_dir='lsun-sofa-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-tower';          dataset = EasyDict(tfrecord_dir='lsun-tower-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-train';          dataset = EasyDict(tfrecord_dir='lsun-train-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-tvmonitor';      dataset = EasyDict(tfrecord_dir='lsun-tvmonitor-100k');      train.mirror_augment = True\n",
    "\n",
    "    # Conditioning & snapshot options.\n",
    "    #desc += '-cond'; dataset.max_label_size = 'full' # conditioned on full label\n",
    "    #desc += '-cond1'; dataset.max_label_size = 1 # conditioned on first component of the label\n",
    "    #desc += '-g4k'; grid.size = '4k'\n",
    "    #desc += '-grpc'; grid.layout = 'row_per_class'\n",
    "\n",
    "    # Config presets (choose one).\n",
    "    #desc += '-preset-v1-1gpu'; submit_config.num_gpus = 1; D.mbstd_group_size = 16; sched.minibatch_base = 16; sched.minibatch_dict = {256: 14, 512: 6, 1024: 3}; sched.lod_training_kimg = 800; sched.lod_transition_kimg = 800; train.total_kimg = 19000\n",
    "    #desc += '-preset-v2-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}; sched.G_lrate_dict = {1024: 0.0015}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-2gpus'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}; sched.G_lrate_dict = {512: 0.0015, 1024: 0.002}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-4gpus'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}; sched.G_lrate_dict = {256: 0.0015, 512: 0.002, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-8gpus'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}; sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "\n",
    "    # Numerical precision (choose one).\n",
    "    #desc += '-fp32'; sched.max_minibatch_per_gpu = {256: 16, 512: 8, 1024: 4}\n",
    "    #desc += '-fp16'; G.dtype = 'float16'; D.dtype = 'float16'; G.pixelnorm_epsilon=1e-4; G_opt.use_loss_scaling = True; D_opt.use_loss_scaling = True; sched.max_minibatch_per_gpu = {512: 16, 1024: 8}\n",
    "\n",
    "    # Disable individual features.\n",
    "    #desc += '-nogrowing'; sched.lod_initial_resolution = 1024; sched.lod_training_kimg = 0; sched.lod_transition_kimg = 0; train.total_kimg = 10000\n",
    "    #desc += '-nopixelnorm'; G.use_pixelnorm = False\n",
    "    #desc += '-nowscale'; G.use_wscale = False; D.use_wscale = False\n",
    "    #desc += '-noleakyrelu'; G.use_leakyrelu = False\n",
    "    #desc += '-nosmoothing'; train.G_smoothing_kimg = 0.0\n",
    "    #desc += '-norepeat'; train.minibatch_repeats = 1\n",
    "    #desc += '-noreset'; train.reset_opt_for_new_lod = False\n",
    "\n",
    "    # Special modes.\n",
    "    #desc += '-BENCHMARK'; sched.lod_initial_resolution = 4; sched.lod_training_kimg = 3; sched.lod_transition_kimg = 3; train.total_kimg = (8*2+1)*3; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
    "    #desc += '-BENCHMARK0'; sched.lod_initial_resolution = 1024; train.total_kimg = 10; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
    "    #desc += '-VERBOSE'; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1; train.network_snapshot_ticks = 100\n",
    "    #desc += '-GRAPH'; train.save_tf_graph = True\n",
    "    #desc += '-HIST'; train.save_weight_histograms = True\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Main entry point for training.\n",
    "# Calls the function indicated by 'train' using the selected options.\n",
    "\n",
    "def main():\n",
    "    kwargs = EasyDict(train)\n",
    "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
    "    kwargs.update(dataset_args=dataset, sched_args=sched, grid_args=grid, tf_config=tf_config)\n",
    "    kwargs.submit_config = copy.deepcopy(submit_config)\n",
    "    kwargs.submit_config.run_dir_root = dnnlib.submission.submit.get_template_from_path(config.result_dir)\n",
    "    kwargs.submit_config.run_dir_ignore += config.run_dir_ignore\n",
    "    kwargs.submit_config.run_desc = desc\n",
    "    dnnlib.submit_run(**kwargs)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation and Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "import scipy\n",
    "\n",
    "def main():\n",
    "\n",
    "    tflib.init_tf()\n",
    "\n",
    "    # Load pre-trained network.\n",
    "    # url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
    "    # with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "    ## NOTE: insert model here:\n",
    "    _G, _D, Gs = pickle.load(open(\"C:\\\\Users\\\\jvhua\\\\OneDrive\\\\Desktop\\\\mhxx-armor\\\\stylegan\\\\results\\\\00000-sgan-custom-1gpu\\\\network-snapshot-000140.pkl\", \"rb\"))\n",
    "    # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n",
    "    # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n",
    "    # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n",
    "\n",
    "    grid_size = [2,2]\n",
    "    image_shrink = 1\n",
    "    image_zoom = 1\n",
    "    duration_sec = 60.0\n",
    "    smoothing_sec = 1.0\n",
    "    mp4_fps = 20\n",
    "    mp4_codec = 'libx264'\n",
    "    mp4_bitrate = '5M'\n",
    "    random_seed = 404\n",
    "    mp4_file = 'results/random_grid_%s.mp4' % random_seed\n",
    "    minibatch_size = 8\n",
    "\n",
    "    num_frames = int(np.rint(duration_sec * mp4_fps))\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    # Generate latent vectors\n",
    "    shape = [num_frames, np.prod(grid_size)] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
    "    all_latents = random_state.randn(*shape).astype(np.float32)\n",
    "    import scipy\n",
    "    all_latents = scipy.ndimage.gaussian_filter(all_latents,\n",
    "                   [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape), mode='wrap')\n",
    "    all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n",
    "\n",
    "\n",
    "    def create_image_grid(images, grid_size=None):\n",
    "        assert images.ndim == 3 or images.ndim == 4\n",
    "        num, img_h, img_w, channels = images.shape\n",
    "\n",
    "        if grid_size is not None:\n",
    "            grid_w, grid_h = tuple(grid_size)\n",
    "        else:\n",
    "            grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n",
    "            grid_h = max((num - 1) // grid_w + 1, 1)\n",
    "\n",
    "        grid = np.zeros([grid_h * img_h, grid_w * img_w, channels], dtype=images.dtype)\n",
    "        for idx in range(num):\n",
    "            x = (idx % grid_w) * img_w\n",
    "            y = (idx // grid_w) * img_h\n",
    "            grid[y : y + img_h, x : x + img_w] = images[idx]\n",
    "        return grid\n",
    "\n",
    "    # Frame generation func for moviepy.\n",
    "    def make_frame(t):\n",
    "        frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
    "        latents = all_latents[frame_idx]\n",
    "        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "        images = Gs.run(latents, None, truncation_psi=0.7,\n",
    "                              randomize_noise=False, output_transform=fmt)\n",
    "\n",
    "        grid = create_image_grid(images, grid_size)\n",
    "        if image_zoom > 1:\n",
    "            grid = scipy.ndimage.zoom(grid, [image_zoom, image_zoom, 1], order=0)\n",
    "        if grid.shape[2] == 1:\n",
    "            grid = grid.repeat(3, 2) # grayscale => RGB\n",
    "        return grid\n",
    "\n",
    "    # Generate video.\n",
    "    import moviepy.editor\n",
    "    video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
    "    video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n",
    "\n",
    "    # import scipy\n",
    "    # coarse\n",
    "    duration_sec = 60.0\n",
    "    smoothing_sec = 1.0\n",
    "    mp4_fps = 20\n",
    "\n",
    "    num_frames = int(np.rint(duration_sec * mp4_fps))\n",
    "    random_seed = 500\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "\n",
    "    w = 512\n",
    "    h = 512\n",
    "    #src_seeds = [601]\n",
    "    dst_seeds = [700]\n",
    "    style_ranges = ([0] * 7 + [range(8,16)]) * len(dst_seeds)\n",
    "\n",
    "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    synthesis_kwargs = dict(output_transform=fmt, truncation_psi=0.7, minibatch_size=8)\n",
    "\n",
    "    shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
    "    src_latents = random_state.randn(*shape).astype(np.float32)\n",
    "    src_latents = scipy.ndimage.gaussian_filter(src_latents,\n",
    "                                                smoothing_sec * mp4_fps,\n",
    "                                                mode='wrap')\n",
    "    src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n",
    "\n",
    "    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n",
    "\n",
    "\n",
    "    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
    "    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
    "    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "\n",
    "\n",
    "    canvas = PIL.Image.new('RGB', (w * (len(dst_seeds) + 1), h * 2), 'white')\n",
    "\n",
    "    for col, dst_image in enumerate(list(dst_images)):\n",
    "        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), ((col + 1) * h, 0))\n",
    "\n",
    "    def make_frame(t):\n",
    "        frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
    "        src_image = src_images[frame_idx]\n",
    "        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), (0, h))\n",
    "\n",
    "        for col, dst_image in enumerate(list(dst_images)):\n",
    "            col_dlatents = np.stack([dst_dlatents[col]])\n",
    "            col_dlatents[:, style_ranges[col]] = src_dlatents[frame_idx, style_ranges[col]]\n",
    "            col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "            for row, image in enumerate(list(col_images)):\n",
    "                canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * h, (row + 1) * w))\n",
    "        return np.array(canvas)\n",
    "\n",
    "    # Generate video.\n",
    "    import moviepy.editor\n",
    "    mp4_file = 'results/interpolate.mp4'\n",
    "    mp4_codec = 'libx264'\n",
    "    mp4_bitrate = '5M'\n",
    "\n",
    "    video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
    "    video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n",
    "\n",
    "    import scipy\n",
    "\n",
    "    duration_sec = 60.0\n",
    "    smoothing_sec = 1.0\n",
    "    mp4_fps = 20\n",
    "\n",
    "    num_frames = int(np.rint(duration_sec * mp4_fps))\n",
    "    random_seed = 503\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "\n",
    "    w = 512\n",
    "    h = 512\n",
    "    style_ranges = [range(6,16)]\n",
    "\n",
    "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    synthesis_kwargs = dict(output_transform=fmt, truncation_psi=0.7, minibatch_size=8)\n",
    "\n",
    "    shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n",
    "    src_latents = random_state.randn(*shape).astype(np.float32)\n",
    "    src_latents = scipy.ndimage.gaussian_filter(src_latents,\n",
    "                                                smoothing_sec * mp4_fps,\n",
    "                                                mode='wrap')\n",
    "    src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n",
    "\n",
    "    dst_latents = np.stack([random_state.randn(Gs.input_shape[1])])\n",
    "\n",
    "\n",
    "    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n",
    "    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n",
    "\n",
    "\n",
    "    def make_frame(t):\n",
    "        frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n",
    "        col_dlatents = np.stack([dst_dlatents[0]])\n",
    "        col_dlatents[:, style_ranges[0]] = src_dlatents[frame_idx, style_ranges[0]]\n",
    "        col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n",
    "        return col_images[0]\n",
    "\n",
    "    # Generate video.\n",
    "    import moviepy.editor\n",
    "    mp4_file = 'results/fine_%s.mp4' % (random_seed)\n",
    "    mp4_codec = 'libx264'\n",
    "    mp4_bitrate = '5M'\n",
    "\n",
    "    video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n",
    "    video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'tensflow'",
   "language": "python",
   "name": "tensflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
